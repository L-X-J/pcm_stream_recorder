import Flutter
import UIKit
import AVFoundation

/// è½»é‡çº§åŸç”Ÿå½•éŸ³æ’ä»¶ - iOS å®ç°
/// ä½¿ç”¨ AVAudioEngine å®ç° PCM å®æ—¶å›è°ƒä¸ WAV æ–‡ä»¶å½•åˆ¶
public class PcmStreamRecorderPlugin: NSObject, FlutterPlugin {
  private var methodChannel: FlutterMethodChannel?
  private var eventChannel: FlutterEventChannel?
  private var eventSink: FlutterEventSink?
  private var routeChangeObserver: NSObjectProtocol?
  
  private var audioEngine: AVAudioEngine?
  private var inputNode: AVAudioInputNode?
  private var isRecording = false
  private var resamplePosition: Double = 0.0
  private var enableLog = false
  
  // å½•éŸ³é…ç½®
  private var sampleRate: Int = 16000
  private var channels: Int = 1
  private var bufferSize: Int = 1600
  
  // è°ƒè¯•è®¡æ•°å™¨
  private var sendCount: Int = 0
  private var zeroFrameStreak: Int = 0
  private var isHealingRoute: Bool = false
  
  private let stopQueue = DispatchQueue(label: "pcm.recorder.stop", qos: .userInitiated)
  private static let deactivateQueue = DispatchQueue(label: "pcm.recorder.deactivate", qos: .userInitiated)
  private static let sessionQueue = DispatchQueue(label: "pcm.recorder.session", qos: .userInitiated)
  private static var savedCategory: AVAudioSession.Category?
  private static var savedMode: AVAudioSession.Mode?
  private static var savedOptions: AVAudioSession.CategoryOptions = []
  private static var savedPreferredSampleRate: Double?

  private func log(_ message: String) {
    if enableLog {
      print("[PcmStreamRecorder] \(message)")
    }
  }


  private func startObservingRouteChanges() {
    stopObservingRouteChanges()
    routeChangeObserver = NotificationCenter.default.addObserver(
      forName: AVAudioSession.routeChangeNotification,
      object: nil,
      queue: .main
    ) { [weak self] _ in
      DispatchQueue.main.asyncAfter(deadline: .now() + 0.15) {
        guard let self = self, self.isRecording else { return }
        self.reconfigureInputTap()
      }
    }
  }

  private func stopObservingRouteChanges() {
    if let observer = routeChangeObserver {
      NotificationCenter.default.removeObserver(observer)
      routeChangeObserver = nil
    }
  }
  
  public static func register(with registrar: FlutterPluginRegistrar) {
    let instance = PcmStreamRecorderPlugin()
    
    // MethodChannel ç”¨äºæ–¹æ³•è°ƒç”¨
    let methodChannel = FlutterMethodChannel(
      name: "pcm_stream_recorder",
      binaryMessenger: registrar.messenger()
    )
    instance.methodChannel = methodChannel
    
    // EventChannel ç”¨äºæµå¼ä¼ è¾“ PCM æ•°æ®
    let eventChannel = FlutterEventChannel(
      name: "pcm_stream_recorder/audio_stream",
      binaryMessenger: registrar.messenger()
    )
    eventChannel.setStreamHandler(instance)
    instance.eventChannel = eventChannel
    
    // æ³¨å†Œ MethodChannel å¤„ç†å™¨
    registrar.addMethodCallDelegate(instance, channel: methodChannel)
  }
  
  public func handle(_ call: FlutterMethodCall, result: @escaping FlutterResult) {
    switch call.method {
    case "checkPermission":
      checkPermission(result: result)
      
    case "requestPermission":
      requestPermission(result: result)
      
    case "start":
      guard let args = call.arguments as? [String: Any] else {
        result(FlutterError(
          code: "INVALID_ARGUMENT",
          message: "å‚æ•°æ ¼å¼é”™è¯¯",
          details: nil
        ))
        return
      }
      startRecording(
        sampleRate: args["sampleRate"] as? Int ?? 16000,
        channels: args["channels"] as? Int ?? 1,
        bufferSize: args["bufferSize"] as? Int ?? 1600,
        enableLog: args["enableLog"] as? Bool ?? false,
        result: result
      )
      
    case "stop":
      stopRecording(result: result)
      
    case "deactivateSession":
      PcmStreamRecorderPlugin.deactivateSession(result: result)
    
    case "prepareAudioSession":
      PcmStreamRecorderPlugin.prepareAudioSession(result: result)
    
    case "restoreAudioSession":
      PcmStreamRecorderPlugin.restoreAudioSession(result: result)
      
    case "pause":
      pauseRecording(result: result)
      
    case "resume":
      resumeRecording(result: result)
      
    case "isRecording":
      result(isRecording)
      
    default:
      result(FlutterMethodNotImplemented)
    }
  }
  
  /// æ£€æŸ¥å½•éŸ³æƒé™
  private func checkPermission(result: @escaping FlutterResult) {
    let status = AVAudioSession.sharedInstance().recordPermission
    switch status {
    case .granted:
      result(true)
    case .denied:
      result(false)
    case .undetermined:
      result(false)
    @unknown default:
      result(false)
    }
  }
  
  /// è¯·æ±‚å½•éŸ³æƒé™
  private func requestPermission(result: @escaping FlutterResult) {
    AVAudioSession.sharedInstance().requestRecordPermission { granted in
      DispatchQueue.main.async {
        result(granted)
      }
    }
  }
  
  /// å¼€å§‹å½•éŸ³
  private func startRecording(
    sampleRate: Int,
    channels: Int,
    bufferSize: Int,
    enableLog: Bool,
    result: @escaping FlutterResult
  ) {
    guard !isRecording else {
      result(FlutterError(
        code: "ALREADY_RECORDING",
        message: "å½•éŸ³å·²åœ¨è¿›è¡Œä¸­",
        details: nil
      ))
      return
    }
    
    // éªŒè¯å‚æ•°æœ‰æ•ˆæ€§
    guard sampleRate > 0 else {
      result(FlutterError(
        code: "INVALID_ARGUMENT",
        message: "é‡‡æ ·ç‡å¿…é¡»å¤§äº 0ï¼Œå½“å‰å€¼: \(sampleRate)",
        details: nil
      ))
      return
    }
    
    guard channels == 1 || channels == 2 else {
      result(FlutterError(
        code: "INVALID_ARGUMENT",
        message: "å£°é“æ•°å¿…é¡»ä¸º 1ï¼ˆå•å£°é“ï¼‰æˆ– 2ï¼ˆç«‹ä½“å£°ï¼‰ï¼Œå½“å‰å€¼: \(channels)",
        details: nil
      ))
      return
    }
    
    guard bufferSize > 0 else {
      result(FlutterError(
        code: "INVALID_ARGUMENT",
        message: "ç¼“å†²åŒºå¤§å°å¿…é¡»å¤§äº 0ï¼Œå½“å‰å€¼: \(bufferSize)",
        details: nil
      ))
      return
    }
    
    // æ£€æŸ¥æƒé™
    let permissionStatus = AVAudioSession.sharedInstance().recordPermission
    guard permissionStatus == .granted else {
      result(FlutterError(
        code: "PERMISSION_DENIED",
        message: "å½•éŸ³æƒé™æœªæˆäºˆ",
        details: nil
      ))
      return
    }
    
    self.sampleRate = sampleRate
    self.channels = channels
    self.bufferSize = bufferSize
    self.enableLog = enableLog
    self.resamplePosition = 0.0
    
    do {
      // åˆ›å»ºéŸ³é¢‘å¼•æ“
      let engine = AVAudioEngine()
      let inputNode = engine.inputNode
      
      // è·å–è¾“å…¥æ ¼å¼
      let inputFormat = inputNode.inputFormat(forBus: 0)
      
      // åˆ›å»ºç›®æ ‡æ ¼å¼ï¼ˆ16-bit PCMï¼ŒæŒ‡å®šé‡‡æ ·ç‡å’Œå£°é“æ•°ï¼‰
      // æ³¨æ„ï¼šå³ä½¿å‚æ•°å·²éªŒè¯ï¼ŒAVAudioFormat ä»å¯èƒ½å› ç³»ç»Ÿé™åˆ¶è€Œåˆ›å»ºå¤±è´¥
      guard let targetFormat = AVAudioFormat(
        commonFormat: .pcmFormatInt16,
        sampleRate: Double(sampleRate),
        channels: AVAudioChannelCount(channels),
        interleaved: false
      ) else {
        result(FlutterError(
          code: "FORMAT_ERROR",
          message: "æ— æ³•åˆ›å»ºç›®æ ‡éŸ³é¢‘æ ¼å¼ï¼šé‡‡æ ·ç‡=\(sampleRate)Hz, å£°é“æ•°=\(channels)ã€‚è¯·æ£€æŸ¥å‚æ•°æ˜¯å¦åœ¨ç³»ç»Ÿæ”¯æŒçš„èŒƒå›´å†…ã€‚",
          details: "sampleRate: \(sampleRate), channels: \(channels)"
        ))
        return
      }
      
      // å¦‚æœé‡‡æ ·ç‡æˆ–å£°é“æ•°ä¸åŒ¹é…ï¼Œéœ€è¦è½¬æ¢
      let needsConversion = inputFormat.sampleRate != Double(sampleRate) || 
                           inputFormat.channelCount != AVAudioChannelCount(channels)
      
      // ç¡®ä¿åœ¨å®‰è£…æ–° tap ä¹‹å‰ç§»é™¤å¯èƒ½å­˜åœ¨çš„æ—§ tap
      // è¿™å¯ä»¥é˜²æ­¢åœ¨é‡æ–°å¯åŠ¨å½•éŸ³æ—¶å‡ºç° "Tap already exists" é”™è¯¯
      inputNode.removeTap(onBus: 0)
      
      if needsConversion {
        // å®‰è£… tap æ¥æ¥æ”¶åŸå§‹ PCM æ•°æ®ï¼Œæ‰‹åŠ¨é‡é‡‡æ ·ä¸º Int16 PCM
        inputNode.installTap(
          onBus: 0,
          bufferSize: AVAudioFrameCount(bufferSize * 4), // æ›´å¤§çš„ buffer ç”¨äºè½¬æ¢
          format: inputFormat
        ) { [weak self] buffer, time in
          guard let self = self, self.isRecording else { return }
          self.processBufferWithResample(
            buffer,
            inputFormat: inputFormat,
            targetSampleRate: targetFormat.sampleRate,
            targetChannels: Int(targetFormat.channelCount)
          )
        }
      } else {
        // æ ¼å¼åŒ¹é…ï¼Œç›´æ¥ä½¿ç”¨
        inputNode.installTap(
          onBus: 0,
          bufferSize: AVAudioFrameCount(bufferSize),
          format: inputFormat
        ) { [weak self] buffer, time in
          guard let self = self, self.isRecording else { return }
          self.sendPCMData(buffer)
        }
      }
      
      // å¯åŠ¨å¼•æ“
      try engine.start()
      
      self.audioEngine = engine
      self.inputNode = inputNode
      self.isRecording = true
      
      log("å½•éŸ³å·²å¯åŠ¨")
      log("ç›®æ ‡é‡‡æ ·ç‡: \(sampleRate)Hz, å£°é“: \(channels), ç¼“å†²åŒº: \(bufferSize)")
      log("è¾“å…¥æ ¼å¼: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)ch, \(inputFormat.commonFormat.rawValue)")
      log("ç›®æ ‡æ ¼å¼: \(targetFormat.sampleRate)Hz, \(targetFormat.channelCount)ch, \(targetFormat.commonFormat.rawValue)")
      log("éœ€è¦è½¬æ¢: \(needsConversion)")
      
      // æ£€æŸ¥ eventSink æ˜¯å¦å·²è¿æ¥ï¼ˆåº”è¯¥åœ¨ Dart ç«¯è°ƒç”¨ listen() æ—¶å·²è®¾ç½®ï¼‰
      if eventSink == nil {
        log("âš ï¸ è­¦å‘Š: eventSink æœªè¿æ¥ï¼ŒPCM æ•°æ®å¯èƒ½æ— æ³•å‘é€åˆ° Flutter")
        log("è¯·ç¡®ä¿åœ¨è°ƒç”¨ start() ä¹‹å‰å·²è°ƒç”¨ receiveBroadcastStream().listen()")
      } else {
        log("âœ… eventSink å·²è¿æ¥ï¼Œå¯ä»¥æ­£å¸¸å‘é€ PCM æ•°æ®")
      }
      
      startObservingRouteChanges()
      result(true)
    } catch {
      result(FlutterError(
        code: "START_FAILED",
        message: "å¯åŠ¨å½•éŸ³å¤±è´¥: \(error.localizedDescription)",
        details: error.localizedDescription
      ))
    }
  }
  
  /// å‘é€ PCM æ•°æ®åˆ° Flutter
  private func sendPCMData(_ buffer: AVAudioPCMBuffer) {
    let frameLength = Int(buffer.frameLength)
    let channelCount = Int(buffer.format.channelCount)
    
    // æ£€æŸ¥ buffer æ ¼å¼å¹¶è½¬æ¢
    var pcmData: Data
    var maxAmplitude: Int16 = 0
    var sampleCount: Int = 0
    
    if let int16Data = buffer.int16ChannelData {
      // å·²ç»æ˜¯ int16 æ ¼å¼ï¼Œç›´æ¥è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„ï¼ˆå°ç«¯åºï¼‰
      let dataSize = frameLength * channelCount * 2 // 16-bit = 2 bytes
      pcmData = Data(count: dataSize)
      
      pcmData.withUnsafeMutableBytes { bytes in
        let int16Pointer = bytes.bindMemory(to: Int16.self)
        var index = 0
        for frame in 0..<frameLength {
          for channel in 0..<channelCount {
            // ç›´æ¥ä½¿ç”¨å°ç«¯åºï¼ˆiOS æœ¬èº«å°±æ˜¯å°ç«¯åºï¼‰
            let sample = int16Data[channel][frame]
            int16Pointer[index] = sample
            maxAmplitude = max(maxAmplitude, abs(sample))
            sampleCount += 1
            index += 1
          }
        }
      }
    } else if let float32Data = buffer.floatChannelData {
      // éœ€è¦ä» float32 è½¬æ¢ä¸º int16
      let dataSize = frameLength * channelCount * 2 // 16-bit = 2 bytes
      pcmData = Data(count: dataSize)
      
      pcmData.withUnsafeMutableBytes { bytes in
        let int16Pointer = bytes.bindMemory(to: Int16.self)
        var index = 0
        for frame in 0..<frameLength {
          for channel in 0..<channelCount {
            let floatSample = float32Data[channel][frame]
            // é™åˆ¶èŒƒå›´ [-1.0, 1.0] å¹¶è½¬æ¢ä¸º int16
            let clampedSample = max(-1.0, min(1.0, floatSample))
            let int16Sample = Int16(clampedSample * 32767.0)
            int16Pointer[index] = int16Sample
            maxAmplitude = max(maxAmplitude, abs(int16Sample))
            sampleCount += 1
            index += 1
          }
        }
      }
    } else {
      // ä¸æ”¯æŒçš„æ ¼å¼
      log("ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: \(buffer.format)")
      return
    }
    
    // æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
    guard pcmData.count > 0 else {
      log("âš ï¸ è­¦å‘Š: PCM æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å‘é€")
      return
    }
    
    // EventChannel å¿…é¡»åœ¨ä¸»çº¿ç¨‹è°ƒç”¨
    emitPCMData(pcmData)
    if enableLog {
      log("å‘é€ PCM æ•°æ®ï¼Œå¸§æ•°: \(frameLength)ï¼Œé€šé“: \(channelCount)ï¼Œå­—èŠ‚: \(pcmData.count)ï¼Œæœ€å¤§å¹…åº¦: \(maxAmplitude)ï¼Œé‡‡æ ·æ•°: \(sampleCount)")
    }
    // æ£€æµ‹è¿ç»­é™éŸ³å¸§ï¼Œå°è¯•è‡ªæ„ˆè¾“å…¥ç®¡çº¿ï¼ˆè“ç‰™è·¯ç”±åˆ‡æ¢åå¸¸è§ï¼‰
    if maxAmplitude == 0 {
      zeroFrameStreak += 1
    } else {
      zeroFrameStreak = 0
    }
    if zeroFrameStreak >= 8, !isHealingRoute, isRecording {
      isHealingRoute = true
      DispatchQueue.main.async { [weak self] in
        guard let self = self else { return }
        self.reconfigureInputTap()
        self.zeroFrameStreak = 0
        self.isHealingRoute = false
        if self.enableLog { self.log("å·²è§¦å‘è·¯ç”±è‡ªæ„ˆï¼šå·²é‡å¯éŸ³é¢‘å¼•æ“å¹¶é‡è£… tap") }
      }
    }
  }
  
  /// å‘é€ PCM æ•°æ® (Data)
  private func emitPCMData(_ pcmData: Data) {
    guard !pcmData.isEmpty else { return }
    DispatchQueue.main.async { [weak self] in
      guard let self = self else { return }
      guard let eventSink = self.eventSink else {
        log("âš ï¸ eventSink ä¸º nilï¼Œæ•°æ®å·²ä¸¢å¼ƒ (å¤§å°: \(pcmData.count) bytes)")
        return
      }
      eventSink(FlutterStandardTypedData(bytes: pcmData))
      self.sendCount += 1
      if self.sendCount <= 5 {
        log("âœ… å·²å‘é€ PCM æ•°æ® #\(self.sendCount)ï¼Œå¤§å°: \(pcmData.count) bytes")
      }
    }
  }
  
  /// å¤„ç†éœ€è¦é‡é‡‡æ ·çš„éŸ³é¢‘ç¼“å†²
  private func processBufferWithResample(
    _ buffer: AVAudioPCMBuffer,
    inputFormat: AVAudioFormat,
    targetSampleRate: Double,
    targetChannels: Int
  ) {
    let inputFrames = Int(buffer.frameLength)
    guard inputFrames > 0 else { return }
    
    let inputSampleRate = inputFormat.sampleRate
    guard inputSampleRate > 0, targetSampleRate > 0 else { return }
    
    let ratio = inputSampleRate / targetSampleRate
    guard ratio > 0 else { return }
    
    let channelCount = Int(inputFormat.channelCount)
    guard channelCount > 0 else { return }
    
    log("ğŸ™ï¸ è¾“å…¥å¸§æ•°: \(inputFrames) (éœ€è¦é‡é‡‡æ · ratio=\(ratio))")
    
    var monoBuffer = [Float](repeating: 0.0, count: inputFrames)
    if let floatChannels = buffer.floatChannelData {
      let stride = buffer.stride
      for ch in 0..<channelCount {
        let channelData = floatChannels[ch]
        for i in 0..<inputFrames {
          monoBuffer[i] += channelData[i * stride]
        }
      }
      if channelCount > 1 {
        let inv = 1.0 / Float(channelCount)
        for i in 0..<inputFrames {
          monoBuffer[i] *= inv
        }
      }
    } else if let int16Channels = buffer.int16ChannelData {
      let stride = buffer.stride
      for ch in 0..<channelCount {
        let channelData = int16Channels[ch]
        for i in 0..<inputFrames {
          monoBuffer[i] += Float(channelData[i * stride]) / 32768.0
        }
      }
      if channelCount > 1 {
        let inv = 1.0 / Float(channelCount)
        for i in 0..<inputFrames {
          monoBuffer[i] *= inv
        }
      }
    } else {
      log("âŒ ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: \(inputFormat.commonFormat.rawValue)")
      return
    }
    
    var position = resamplePosition
    var outputSamples = [Int16]()
    outputSamples.reserveCapacity(Int(Double(inputFrames) / ratio) + 1)
    let lastIndex = max(inputFrames - 1, 0)
    
    while position < Double(inputFrames) {
      let idx = Int(position)
      let frac = Float(position - Double(idx))
      let nextIdx = min(idx + 1, lastIndex)
      let current = monoBuffer[idx]
      let next = monoBuffer[nextIdx]
      let interpolated = current + frac * (next - current)
      let clamped = max(-1.0, min(1.0, interpolated))
      let sample = Int16(clamped * 32767.0)
      outputSamples.append(sample)
      position += ratio
    }
    
    resamplePosition = position - Double(inputFrames)
    if resamplePosition >= ratio {
      resamplePosition.formTruncatingRemainder(dividingBy: ratio)
    }
    
    if outputSamples.isEmpty {
      log("âš ï¸ é‡é‡‡æ ·åæ— å¯ç”¨æ•°æ®")
      return
    }
    
    let outputFrameCount = outputSamples.count
    let outputChannels = max(targetChannels, 1)
    let bytesPerSample = 2 // Int16
    var maxAmplitude: Int16 = 0
    var pcmData = Data(count: outputFrameCount * outputChannels * bytesPerSample)
    pcmData.withUnsafeMutableBytes { rawBuffer in
      let buffer = rawBuffer.bindMemory(to: Int16.self)
      guard let baseAddress = buffer.baseAddress else { return }
      for frame in 0..<outputFrameCount {
        let sample = outputSamples[frame]
        maxAmplitude = max(maxAmplitude, abs(sample))
        for ch in 0..<outputChannels {
          baseAddress[frame * outputChannels + ch] = sample
        }
      }
    }
    
    log("âœ… é‡é‡‡æ ·æˆåŠŸï¼Œè¾“å‡ºå¸§æ•°: \(outputFrameCount)ï¼Œå­—èŠ‚: \(pcmData.count)ï¼Œæœ€å¤§å¹…åº¦: \(maxAmplitude)")
    emitPCMData(pcmData)
  }
  
  /// åœæ­¢å½•éŸ³
  private func stopRecording(result: @escaping FlutterResult) {
    guard isRecording else {
      result(false)
      return
    }
    
    isRecording = false
    sendCount = 0
    stopObservingRouteChanges()
    let engine = audioEngine
    let node = inputNode
    stopQueue.async { [weak self] in
      guard let self = self else { return }
      node?.removeTap(onBus: 0)
      engine?.stop()
      self.audioEngine = nil
      self.inputNode = nil
      self.resamplePosition = 0.0
      DispatchQueue.main.async {
        result(true)
      }
    }
  }

  public static func deactivateSession(result: @escaping FlutterResult) {
    deactivateQueue.async {
      let audioSession = AVAudioSession.sharedInstance()
      do {
        try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
        DispatchQueue.main.async { result(true) }
      } catch {
        DispatchQueue.main.async {
          result(FlutterError(code: "DEACTIVATE_FAILED", message: error.localizedDescription, details: error.localizedDescription))
        }
      }
    }
  }

  public static func prepareAudioSession(result: @escaping FlutterResult) {
    sessionQueue.async {
      let audioSession = AVAudioSession.sharedInstance()
      do {
        if savedCategory == nil {
          savedCategory = audioSession.category
          savedMode = audioSession.mode
          savedOptions = audioSession.categoryOptions
          savedPreferredSampleRate = audioSession.preferredSampleRate
        }
        var options: AVAudioSession.CategoryOptions = [.allowBluetooth]
        if savedOptions.contains(.mixWithOthers) {
          options.insert(.mixWithOthers)
        }
        try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: options)
        try audioSession.setPreferredSampleRate(16000)
        try audioSession.setActive(true, options: [])
        DispatchQueue.main.async { result(true) }
      } catch {
        DispatchQueue.main.async {
          result(FlutterError(code: "PREPARE_SESSION_FAILED", message: error.localizedDescription, details: error.localizedDescription))
        }
      }
    }
  }

  public static func restoreAudioSession(result: @escaping FlutterResult) {
    sessionQueue.async {
      let audioSession = AVAudioSession.sharedInstance()
      do {
        try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
        if let category = savedCategory {
          let mode = savedMode ?? .default
          let options = savedOptions
          try audioSession.setCategory(category, mode: mode, options: options)
          if let preferredRate = savedPreferredSampleRate {
            try? audioSession.setPreferredSampleRate(preferredRate)
          }
          savedCategory = nil
          savedMode = nil
          savedOptions = []
          savedPreferredSampleRate = nil
        } else {
          try audioSession.setCategory(.playback, mode: .default, options: [])
        }
        DispatchQueue.main.async { result(true) }
      } catch {
        DispatchQueue.main.async {
          result(FlutterError(code: "RESTORE_SESSION_FAILED", message: error.localizedDescription, details: error.localizedDescription))
        }
      }
    }
  }
  
  
  /// æš‚åœå½•éŸ³ï¼ˆiOS ä¸æ”¯æŒçœŸæ­£çš„æš‚åœï¼Œè¿™é‡Œåœæ­¢ tapï¼‰
  private func pauseRecording(result: @escaping FlutterResult) {
    guard isRecording else {
      result(false)
      return
    }
    
    inputNode?.removeTap(onBus: 0)
    result(true)
  }
  
  /// æ¢å¤å½•éŸ³
  private func resumeRecording(result: @escaping FlutterResult) {
    guard isRecording, let engine = audioEngine, let inputNode = inputNode else {
      result(false)
      return
    }
    
    // éªŒè¯å‚æ•°æœ‰æ•ˆæ€§ï¼ˆé˜²æ­¢åœ¨æ¢å¤æ—¶ä½¿ç”¨æ— æ•ˆå‚æ•°ï¼‰
    guard sampleRate > 0 && (channels == 1 || channels == 2) else {
      result(FlutterError(
        code: "INVALID_STATE",
        message: "å½•éŸ³çŠ¶æ€å¼‚å¸¸ï¼šé‡‡æ ·ç‡=\(sampleRate)Hz, å£°é“æ•°=\(channels)ã€‚è¯·é‡æ–°å¯åŠ¨å½•éŸ³ã€‚",
        details: nil
      ))
      return
    }
    
    let inputFormat = inputNode.inputFormat(forBus: 0)
    let targetSampleRate = Double(sampleRate)
    let targetChannels = channels
    let needsConversion = inputFormat.sampleRate != targetSampleRate ||
      inputFormat.channelCount != AVAudioChannelCount(targetChannels)

    let tapBufferSize = needsConversion ? AVAudioFrameCount(bufferSize * 4) : AVAudioFrameCount(bufferSize)

    // ç¡®ä¿åœ¨å®‰è£…æ–° tap ä¹‹å‰ç§»é™¤å¯èƒ½å­˜åœ¨çš„æ—§ tap
    // è¿™å¯ä»¥é˜²æ­¢åœ¨æ¢å¤å½•éŸ³æ—¶å‡ºç° "Tap already exists" é”™è¯¯
    inputNode.removeTap(onBus: 0)

    inputNode.installTap(
      onBus: 0,
      bufferSize: tapBufferSize,
      format: inputFormat
    ) { [weak self] buffer, time in
      guard let self = self, self.isRecording else { return }
      if needsConversion {
        self.processBufferWithResample(
          buffer,
          inputFormat: inputFormat,
          targetSampleRate: targetSampleRate,
          targetChannels: targetChannels
        )
      } else {
        self.sendPCMData(buffer)
      }
    }
    
    result(true)
  }

  private func reconfigureInputTap() {
    guard isRecording, let inputNode = inputNode else { return }
    let inputFormat = inputNode.inputFormat(forBus: 0)
    let targetSampleRate = Double(sampleRate)
    let targetChannels = channels
    let needsConversion = inputFormat.sampleRate != targetSampleRate ||
      inputFormat.channelCount != AVAudioChannelCount(targetChannels)

    let tapBufferSize = needsConversion ? AVAudioFrameCount(bufferSize * 4) : AVAudioFrameCount(bufferSize)
    inputNode.removeTap(onBus: 0)
    // ä¸ºé€‚é…è“ç‰™è·¯ç”±åˆ‡æ¢ï¼Œé‡å¯å¹¶é‡ç½®å¼•æ“
    do {
      try audioEngine?.start()
    } catch {
      audioEngine?.stop()
      audioEngine?.reset()
      do {
        try audioEngine?.start()
        log("å·²åœ¨è·¯ç”±å˜æ›´åé‡å¯éŸ³é¢‘å¼•æ“")
      } catch {
        log("é‡å¯éŸ³é¢‘å¼•æ“å¤±è´¥: \(error.localizedDescription)")
      }
    }
    inputNode.installTap(
      onBus: 0,
      bufferSize: tapBufferSize,
      format: inputFormat
    ) { [weak self] buffer, time in
      guard let self = self, self.isRecording else { return }
      if needsConversion {
        self.processBufferWithResample(
          buffer,
          inputFormat: inputFormat,
          targetSampleRate: targetSampleRate,
          targetChannels: targetChannels
        )
      } else {
        self.sendPCMData(buffer)
      }
    }
  }
}

// MARK: - FlutterStreamHandler
extension PcmStreamRecorderPlugin: FlutterStreamHandler {
  public func onListen(
    withArguments arguments: Any?,
    eventSink events: @escaping FlutterEventSink
  ) -> FlutterError? {
    log("EventChannel onListen called")
    eventSink = events
    return nil
  }
  
  public func onCancel(withArguments arguments: Any?) -> FlutterError? {
    log("EventChannel onCancel called")
    eventSink = nil
    return nil
  }
}
